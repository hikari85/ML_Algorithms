{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "pKoPveSma__f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 1200)\n",
        "        self.fc2 = nn.Linear(1200, 1200)\n",
        "        self.fc3 = nn.Linear(1200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "k4BH5HI2bCr1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 800)\n",
        "        self.fc2 = nn.Linear(800, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4GhhkMWhbEpP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzArprHybIFu",
        "outputId": "6a2aa17f-7e39-499c-9f22-184847bed59f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.08MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
        "    soft_teacher = F.softmax(teacher_logits / temperature, dim=1)\n",
        "    soft_student = F.log_softmax(student_logits / temperature, dim=1)\n",
        "    kl_div = F.kl_div(soft_student, soft_teacher) * (temperature ** 2)\n",
        "    ce_loss = F.cross_entropy(student_logits, labels)\n",
        "    return alpha * kl_div + (1 - alpha) * ce_loss"
      ],
      "metadata": {
        "id": "pyvMKTYHbKZJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = TeacherModel()\n",
        "optimizer = optim.Adam(teacher.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ihjNAuYHbOuQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_teacher(model, train_loader, optimizer, criterion, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Teacher Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "train_teacher(teacher, train_loader, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXiVzTkbbm9K",
        "outputId": "72263be2-0c23-4f8d-ff83-5148b72ec2a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Epoch 1/5, Loss: 0.15537524223327637\n",
            "Teacher Epoch 2/5, Loss: 0.08175810426473618\n",
            "Teacher Epoch 3/5, Loss: 0.06320998817682266\n",
            "Teacher Epoch 4/5, Loss: 0.03392382711172104\n",
            "Teacher Epoch 5/5, Loss: 0.052018385380506516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student = StudentModel()\n",
        "optimizer = optim.Adam(student.parameters(), lr=0.001)\n",
        "\n",
        "def train_student(student, teacher, train_loader, optimizer, temperature=5.0, alpha=0.7, epochs=5):\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            student_logits = student(data)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(data)\n",
        "            loss = distillation_loss(student_logits, teacher_logits, target, temperature, alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Student Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "train_student(student, teacher, train_loader, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWDM0KZCbvYJ",
        "outputId": "48f64ae6-0d02-4093-e532-08cc2cbdf140"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3384: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Epoch 1/5, Loss: 0.08873867988586426\n",
            "Student Epoch 2/5, Loss: 0.06417994201183319\n",
            "Student Epoch 3/5, Loss: 0.036623209714889526\n",
            "Student Epoch 4/5, Loss: 0.050203971564769745\n",
            "Student Epoch 5/5, Loss: 0.04533858597278595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())"
      ],
      "metadata": {
        "id": "WtVLugy9cbrp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_params = count_parameters(teacher)\n",
        "student_params = count_parameters(student)\n",
        "\n",
        "teacher_accuracy = evaluate(teacher, test_loader)\n",
        "student_accuracy = evaluate(student, test_loader)\n",
        "\n",
        "print(f\"Teacher Model Parameters: {teacher_params}\")\n",
        "print(f\"Student Model Parameters: {student_params}\")\n",
        "\n",
        "print(f\"Teacher Accuracy: {teacher_accuracy:.2f}%, Parameters: {teacher_params}\")\n",
        "print(f\"Student Accuracy: {student_accuracy:.2f}%, Parameters: {student_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEpCrERMcdao",
        "outputId": "7c3940e8-ab7f-46df-8395-8d2221ff1e96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model Parameters: 2395210\n",
            "Student Model Parameters: 636010\n",
            "Teacher Accuracy: 97.32%, Parameters: 2395210\n",
            "Student Accuracy: 97.56%, Parameters: 636010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTYVUSzUjn95",
        "outputId": "db642a1e-f366-4c26-bf87-4bf9c003109c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Dummy input tensor for tracing (MNIST image size is 1x28x28)\n",
        "dummy_input = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "# Export Teacher model\n",
        "torch.onnx.export(teacher, dummy_input, \"teacher_model.onnx\", input_names=[\"input\"], output_names=[\"output\"], opset_version=11)\n",
        "\n",
        "# Export Student model\n",
        "torch.onnx.export(student, dummy_input, \"student_model.onnx\", input_names=[\"input\"], output_names=[\"output\"], opset_version=11)\n"
      ],
      "metadata": {
        "id": "UbxCwPjljfws"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}